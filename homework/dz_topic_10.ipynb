{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3235802,"sourceType":"datasetVersion","datasetId":1961542},{"sourceId":9801,"sourceType":"datasetVersion","datasetId":6763}],"dockerImageVersionId":30775,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re\n\nimport pandas as pd\nimport numpy as np\n\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\nimport gensim\nfrom gensim.models import word2vec\nfrom gensim.models import KeyedVectors #  implements word vectors\n\nfrom sklearn.metrics import roc_auc_score, accuracy_score, f1_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n\nimport spacy\n\nfrom tqdm.auto import tqdm\ntqdm.pandas()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-02T19:23:41.622977Z","iopub.execute_input":"2024-10-02T19:23:41.623594Z","iopub.status.idle":"2024-10-02T19:23:41.633250Z","shell.execute_reply.started":"2024-10-02T19:23:41.623543Z","shell.execute_reply":"2024-10-02T19:23:41.631884Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"## Data preparation","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/email-spam-detection-dataset-classification/spam.csv', encoding='latin-1')\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:37:12.362812Z","iopub.execute_input":"2024-10-02T18:37:12.363530Z","iopub.status.idle":"2024-10-02T18:37:12.405149Z","shell.execute_reply.started":"2024-10-02T18:37:12.363482Z","shell.execute_reply":"2024-10-02T18:37:12.403873Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"     v1                                                 v2 Unnamed: 2  \\\n0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n1   ham                      Ok lar... Joking wif u oni...        NaN   \n2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n3   ham  U dun say so early hor... U c already then say...        NaN   \n4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n\n  Unnamed: 3 Unnamed: 4  \n0        NaN        NaN  \n1        NaN        NaN  \n2        NaN        NaN  \n3        NaN        NaN  \n4        NaN        NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>v1</th>\n      <th>v2</th>\n      <th>Unnamed: 2</th>\n      <th>Unnamed: 3</th>\n      <th>Unnamed: 4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.info()\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:37:12.407208Z","iopub.execute_input":"2024-10-02T18:37:12.408275Z","iopub.status.idle":"2024-10-02T18:37:12.426969Z","shell.execute_reply.started":"2024-10-02T18:37:12.408229Z","shell.execute_reply":"2024-10-02T18:37:12.425769Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5572 entries, 0 to 5571\nData columns (total 5 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   v1          5572 non-null   object\n 1   v2          5572 non-null   object\n 2   Unnamed: 2  50 non-null     object\n 3   Unnamed: 3  12 non-null     object\n 4   Unnamed: 4  6 non-null      object\ndtypes: object(5)\nmemory usage: 217.8+ KB\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(5572, 5)"},"metadata":{}}]},{"cell_type":"code","source":"# Remove unnecessary columns (Unnamed 2, 3, 4)\ndf = df[['v1', 'v2']]\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:37:12.430251Z","iopub.execute_input":"2024-10-02T18:37:12.431298Z","iopub.status.idle":"2024-10-02T18:37:12.440615Z","shell.execute_reply.started":"2024-10-02T18:37:12.431251Z","shell.execute_reply":"2024-10-02T18:37:12.439428Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(5572, 2)"},"metadata":{}}]},{"cell_type":"code","source":"# Rename columns\ndf.columns = ['label', 'message']","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:37:12.442092Z","iopub.execute_input":"2024-10-02T18:37:12.442769Z","iopub.status.idle":"2024-10-02T18:37:12.452964Z","shell.execute_reply.started":"2024-10-02T18:37:12.442710Z","shell.execute_reply":"2024-10-02T18:37:12.451633Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Create a new column: 0 for 'spam' and 1 for 'ham'\ndf['score'] = df['label'].map({'spam': 0, 'ham': 1})\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:37:12.454852Z","iopub.execute_input":"2024-10-02T18:37:12.455327Z","iopub.status.idle":"2024-10-02T18:37:12.479777Z","shell.execute_reply.started":"2024-10-02T18:37:12.455281Z","shell.execute_reply":"2024-10-02T18:37:12.478397Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"  label                                            message  score\n0   ham  Go until jurong point, crazy.. Available only ...      1\n1   ham                      Ok lar... Joking wif u oni...      1\n2  spam  Free entry in 2 a wkly comp to win FA Cup fina...      0\n3   ham  U dun say so early hor... U c already then say...      1\n4   ham  Nah I don't think he goes to usf, he lives aro...      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>message</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Evaluate the distribution of the target variable\ndf['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:37:12.481441Z","iopub.execute_input":"2024-10-02T18:37:12.481969Z","iopub.status.idle":"2024-10-02T18:37:12.498688Z","shell.execute_reply.started":"2024-10-02T18:37:12.481911Z","shell.execute_reply":"2024-10-02T18:37:12.497510Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"label\nham     4825\nspam     747\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# Droping duplicated records\ndf = df.drop_duplicates().reset_index(drop=True)\n\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:37:12.500074Z","iopub.execute_input":"2024-10-02T18:37:12.500492Z","iopub.status.idle":"2024-10-02T18:37:12.517275Z","shell.execute_reply.started":"2024-10-02T18:37:12.500440Z","shell.execute_reply":"2024-10-02T18:37:12.515809Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(5169, 3)"},"metadata":{}}]},{"cell_type":"code","source":"# Contractions. Source http://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n\ncontractions = { \n\"ain't\": \"am not\",\n\"aren't\": \"are not\",\n\"can't\": \"cannot\",\n\"can't've\": \"cannot have\",\n\"'cause\": \"because\",\n\"could've\": \"could have\",\n\"couldn't\": \"could not\",\n\"couldn't've\": \"could not have\",\n\"didn't\": \"did not\",\n\"doesn't\": \"does not\",\n\"don't\": \"do not\",\n\"hadn't\": \"had not\",\n\"hadn't've\": \"had not have\",\n\"hasn't\": \"has not\",\n\"haven't\": \"have not\",\n\"he'd\": \"he would\",\n\"he'd've\": \"he would have\",\n\"he'll\": \"he will\",\n\"he's\": \"he is\",\n\"how'd\": \"how did\",\n\"how'll\": \"how will\",\n\"how's\": \"how is\",\n\"i'd\": \"i would\",\n\"i'll\": \"i will\",\n\"i'm\": \"i am\",\n\"i've\": \"i have\",\n\"isn't\": \"is not\",\n\"it'd\": \"it would\",\n\"it'll\": \"it will\",\n\"it's\": \"it is\",\n\"let's\": \"let us\",\n\"ma'am\": \"madam\",\n\"mayn't\": \"may not\",\n\"might've\": \"might have\",\n\"mightn't\": \"might not\",\n\"must've\": \"must have\",\n\"mustn't\": \"must not\",\n\"needn't\": \"need not\",\n\"oughtn't\": \"ought not\",\n\"shan't\": \"shall not\",\n\"sha'n't\": \"shall not\",\n\"she'd\": \"she would\",\n\"she'll\": \"she will\",\n\"she's\": \"she is\",\n\"should've\": \"should have\",\n\"shouldn't\": \"should not\",\n\"that'd\": \"that would\",\n\"that's\": \"that is\",\n\"there'd\": \"there had\",\n\"there's\": \"there is\",\n\"they'd\": \"they would\",\n\"they'll\": \"they will\",\n\"they're\": \"they are\",\n\"they've\": \"they have\",\n\"wasn't\": \"was not\",\n\"we'd\": \"we would\",\n\"we'll\": \"we will\",\n\"we're\": \"we are\",\n\"we've\": \"we have\",\n\"weren't\": \"were not\",\n\"what'll\": \"what will\",\n\"what're\": \"what are\",\n\"what's\": \"what is\",\n\"what've\": \"what have\",\n\"where'd\": \"where did\",\n\"where's\": \"where is\",\n\"who'll\": \"who will\",\n\"who's\": \"who is\",\n\"won't\": \"will not\",\n\"wouldn't\": \"would not\",\n\"you'd\": \"you would\",\n\"you'll\": \"you will\",\n\"you're\": \"you are\"\n}","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:37:12.519465Z","iopub.execute_input":"2024-10-02T18:37:12.520007Z","iopub.status.idle":"2024-10-02T18:37:12.533826Z","shell.execute_reply.started":"2024-10-02T18:37:12.519948Z","shell.execute_reply":"2024-10-02T18:37:12.532398Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Stop-words\nstop_words = set(stopwords.words('english')).union({'also', 'would', 'much', 'many'})\n\nnegations = {\n    'aren',\n    \"aren't\",\n    'couldn',\n    \"couldn't\",\n    'didn',\n    \"didn't\",\n    'doesn',\n    \"doesn't\",\n    'don',\n    \"don't\",\n    'hadn',\n    \"hadn't\",\n    'hasn',\n    \"hasn't\",\n    'haven',\n    \"haven't\",\n    'isn',\n    \"isn't\",\n    'mightn',\n    \"mightn't\",\n    'mustn',\n    \"mustn't\",\n    'needn',\n    \"needn't\",\n    'no',\n    'nor',\n    'not',\n    'shan',\n    \"shan't\",\n    'shouldn',\n    \"shouldn't\",\n    'wasn',\n    \"wasn't\",\n    'weren',\n    \"weren't\",\n    'won',\n    \"won't\",\n    'wouldn',\n    \"wouldn't\"\n}\n\nstop_words = stop_words.difference(negations)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:37:12.535940Z","iopub.execute_input":"2024-10-02T18:37:12.536393Z","iopub.status.idle":"2024-10-02T18:37:12.554994Z","shell.execute_reply.started":"2024-10-02T18:37:12.536328Z","shell.execute_reply":"2024-10-02T18:37:12.553822Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"nlp = spacy.load(\"en_core_web_sm\", disable = ['parser','ner'])\n\n# function to clean text\ndef normalize_text(raw_review):\n    \n    # Remove html tags\n    text = re.sub(\"<[^>]*>\", \" \", raw_review) # match <> and everything in between. [^>] - match everything except >\n    \n    # Remove emails\n    text = re.sub(\"\\S*@\\S*[\\s]+\", \" \", text) # match non-whitespace characters, @ and a whitespaces in the end\n    \n    # remove links\n    text = re.sub(\"https?:\\/\\/.*?[\\s]+\", \" \", text) # match http, s - zero or once, //, \n                                                    # any char 0-unlimited, whitespaces in the end\n        \n     # Convert to lower case, split into individual words\n    text = text.lower().split()\n    \n    # Replace contractions with their full versions\n    text = [contractions.get(word) if word in contractions else word \n            for word in text]\n   \n    # Re-splitting for the correct stop-words extraction\n    text = \" \".join(text).split()    \n    \n    # Remove stop words\n    text = [word for word in text if not word in stop_words]\n\n    text = \" \".join(text)\n    \n    # Remove non-letters        \n    text = re.sub(\"[^a-zA-Z' ]\", \"\", text) # match everything except letters and '\n\n    # Lemmatize words. Need to define lemmatizer above\n    doc = nlp(text)\n    text = \" \".join([token.lemma_ for token in doc if len(token.lemma_) > 1 ])\n    \n    # Remove excesive whitespaces\n    text = re.sub(\"[\\s]+\", \" \", text)    \n    \n    # Join the words back into one string separated by space, and return the result.\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:37:12.556854Z","iopub.execute_input":"2024-10-02T18:37:12.557248Z","iopub.status.idle":"2024-10-02T18:37:13.911695Z","shell.execute_reply.started":"2024-10-02T18:37:12.557193Z","shell.execute_reply":"2024-10-02T18:37:13.910439Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df['text_normalized'] = df['message'].progress_apply(normalize_text)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:37:13.913322Z","iopub.execute_input":"2024-10-02T18:37:13.913810Z","iopub.status.idle":"2024-10-02T18:37:37.463283Z","shell.execute_reply.started":"2024-10-02T18:37:13.913767Z","shell.execute_reply":"2024-10-02T18:37:37.461811Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5169 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"674f584abb7343f4ba8286d9ab04cedd"}},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"  label                                            message  score  \\\n0   ham  Go until jurong point, crazy.. Available only ...      1   \n1   ham                      Ok lar... Joking wif u oni...      1   \n2  spam  Free entry in 2 a wkly comp to win FA Cup fina...      0   \n3   ham  U dun say so early hor... U c already then say...      1   \n4   ham  Nah I don't think he goes to usf, he lives aro...      1   \n\n                                     text_normalized  \n0  go jurong point crazy available bugis great wo...  \n1                                ok lar joke wif oni  \n2  free entry wkly comp win fa cup final tkts st ...  \n3                      dun say early hor already say  \n4            nah not think go usf live around though  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>message</th>\n      <th>score</th>\n      <th>text_normalized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n      <td>1</td>\n      <td>go jurong point crazy available bugis great wo...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n      <td>1</td>\n      <td>ok lar joke wif oni</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n      <td>0</td>\n      <td>free entry wkly comp win fa cup final tkts st ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n      <td>1</td>\n      <td>dun say early hor already say</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n      <td>1</td>\n      <td>nah not think go usf live around though</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## LogisticRegression model with BoW and TF-IDF","metadata":{}},{"cell_type":"code","source":"def get_preds(text_column, algorithm, ngrams=(1,1), max_features=5000):\n    # Train-test split using the column for text data\n    X_train, X_test, y_train, y_test = train_test_split(df[text_column], df['score'], test_size=0.2, random_state=42)\n    \n    if algorithm == 'cv':\n        vect = CountVectorizer(max_features=max_features, ngram_range=ngrams).fit(X_train)\n    elif algorithm == 'tfidf':\n        vect = TfidfVectorizer(max_features=max_features, ngram_range=ngrams).fit(X_train)\n    else:\n        raise ValueError('Select correct algorithm: `cv` or `tfidf`')\n    \n    # transform the documents in the training data to a document-term matrix\n\n    X_train_vectorized = vect.transform(X_train)\n    \n    model = LogisticRegression(random_state=42)\n    model.fit(X_train_vectorized, y_train)\n    \n    predictions = model.predict(vect.transform(X_test))\n\n    print('Algorithm: ', algorithm)\n    print('AUC: ', roc_auc_score(y_test, predictions))\n    print('Accuracy: ', accuracy_score(y_test, predictions))\n    print('F1-score: ', f1_score(y_test, predictions))","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:37:37.470510Z","iopub.execute_input":"2024-10-02T18:37:37.470990Z","iopub.status.idle":"2024-10-02T18:37:37.482772Z","shell.execute_reply.started":"2024-10-02T18:37:37.470947Z","shell.execute_reply":"2024-10-02T18:37:37.481293Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"#### CountVectorizer","metadata":{}},{"cell_type":"code","source":"get_preds('message', 'cv')","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:37:37.484542Z","iopub.execute_input":"2024-10-02T18:37:37.485069Z","iopub.status.idle":"2024-10-02T18:37:37.834846Z","shell.execute_reply.started":"2024-10-02T18:37:37.485012Z","shell.execute_reply":"2024-10-02T18:37:37.833499Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Algorithm:  cv\nAUC:  0.9391295915596758\nAccuracy:  0.9796905222437138\nF1-score:  0.9882747068676717\n","output_type":"stream"}]},{"cell_type":"code","source":"get_preds('message', 'cv', (1,2))","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:37:37.836257Z","iopub.execute_input":"2024-10-02T18:37:37.836699Z","iopub.status.idle":"2024-10-02T18:37:38.448872Z","shell.execute_reply.started":"2024-10-02T18:37:37.836658Z","shell.execute_reply":"2024-10-02T18:37:38.447481Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Algorithm:  cv\nAUC:  0.9494744191458827\nAccuracy:  0.9825918762088974\nF1-score:  0.9899328859060402\n","output_type":"stream"}]},{"cell_type":"code","source":"get_preds('message', 'cv', (2,2))","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:37:38.450698Z","iopub.execute_input":"2024-10-02T18:37:38.451212Z","iopub.status.idle":"2024-10-02T18:37:38.925520Z","shell.execute_reply.started":"2024-10-02T18:37:38.451157Z","shell.execute_reply":"2024-10-02T18:37:38.924170Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Algorithm:  cv\nAUC:  0.8442651565106086\nAccuracy:  0.9555125725338491\nF1-score:  0.9747530186608123\n","output_type":"stream"}]},{"cell_type":"code","source":"get_preds('text_normalized', 'cv')","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:37:38.927247Z","iopub.execute_input":"2024-10-02T18:37:38.927663Z","iopub.status.idle":"2024-10-02T18:37:39.159288Z","shell.execute_reply.started":"2024-10-02T18:37:38.927619Z","shell.execute_reply":"2024-10-02T18:37:39.158131Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Algorithm:  cv\nAUC:  0.9224506419456188\nAccuracy:  0.9758220502901354\nF1-score:  0.9860879243183084\n","output_type":"stream"}]},{"cell_type":"code","source":"get_preds('text_normalized', 'cv', (1,2))","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:37:39.160769Z","iopub.execute_input":"2024-10-02T18:37:39.161256Z","iopub.status.idle":"2024-10-02T18:37:39.582501Z","shell.execute_reply.started":"2024-10-02T18:37:39.161202Z","shell.execute_reply":"2024-10-02T18:37:39.581207Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Algorithm:  cv\nAUC:  0.9201272254761258\nAccuracy:  0.97678916827853\nF1-score:  0.9866666666666667\n","output_type":"stream"}]},{"cell_type":"code","source":"get_preds('text_normalized', 'cv', (2,2))","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:37:39.583995Z","iopub.execute_input":"2024-10-02T18:37:39.584437Z","iopub.status.idle":"2024-10-02T18:37:39.916001Z","shell.execute_reply.started":"2024-10-02T18:37:39.584360Z","shell.execute_reply":"2024-10-02T18:37:39.914747Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Algorithm:  cv\nAUC:  0.7586206896551724\nAccuracy:  0.9323017408123792\nF1-score:  0.9621212121212122\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### TfidfVectorizer","metadata":{}},{"cell_type":"code","source":"get_preds('message', 'tfidf')","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:37:39.917392Z","iopub.execute_input":"2024-10-02T18:37:39.917785Z","iopub.status.idle":"2024-10-02T18:37:40.243320Z","shell.execute_reply.started":"2024-10-02T18:37:39.917744Z","shell.execute_reply":"2024-10-02T18:37:40.242038Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Algorithm:  tfidf\nAUC:  0.901760986773205\nAccuracy:  0.9700193423597679\nF1-score:  0.9828064337215752\n","output_type":"stream"}]},{"cell_type":"code","source":"get_preds('message', 'tfidf', (1,2))","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:37:40.245092Z","iopub.execute_input":"2024-10-02T18:37:40.245663Z","iopub.status.idle":"2024-10-02T18:37:40.858294Z","shell.execute_reply.started":"2024-10-02T18:37:40.245604Z","shell.execute_reply":"2024-10-02T18:37:40.857252Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Algorithm:  tfidf\nAUC:  0.903448275862069\nAccuracy:  0.9729206963249516\nF1-score:  0.9844961240310077\n","output_type":"stream"}]},{"cell_type":"code","source":"get_preds('message', 'tfidf', (2,2))","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:37:40.860095Z","iopub.execute_input":"2024-10-02T18:37:40.860623Z","iopub.status.idle":"2024-10-02T18:37:41.338622Z","shell.execute_reply.started":"2024-10-02T18:37:40.860567Z","shell.execute_reply":"2024-10-02T18:37:41.337242Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Algorithm:  tfidf\nAUC:  0.7172413793103448\nAccuracy:  0.9206963249516441\nF1-score:  0.9559139784946237\n","output_type":"stream"}]},{"cell_type":"code","source":"get_preds('text_normalized', 'tfidf')","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:37:41.340212Z","iopub.execute_input":"2024-10-02T18:37:41.340778Z","iopub.status.idle":"2024-10-02T18:37:41.582913Z","shell.execute_reply.started":"2024-10-02T18:37:41.340724Z","shell.execute_reply":"2024-10-02T18:37:41.581627Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Algorithm:  tfidf\nAUC:  0.8690392149257204\nAccuracy:  0.9584139264990329\nF1-score:  0.9762299613045882\n","output_type":"stream"}]},{"cell_type":"code","source":"get_preds('text_normalized', 'tfidf', (1,2))","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:37:41.584245Z","iopub.execute_input":"2024-10-02T18:37:41.584638Z","iopub.status.idle":"2024-10-02T18:37:41.995205Z","shell.execute_reply.started":"2024-10-02T18:37:41.584595Z","shell.execute_reply":"2024-10-02T18:37:41.994020Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Algorithm:  tfidf\nAUC:  0.8644660796710755\nAccuracy:  0.9555125725338491\nF1-score:  0.9745575221238939\n","output_type":"stream"}]},{"cell_type":"code","source":"get_preds('text_normalized', 'tfidf', (2,2))","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:37:41.996701Z","iopub.execute_input":"2024-10-02T18:37:41.997070Z","iopub.status.idle":"2024-10-02T18:37:42.332293Z","shell.execute_reply.started":"2024-10-02T18:37:41.997031Z","shell.execute_reply":"2024-10-02T18:37:42.330867Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Algorithm:  tfidf\nAUC:  0.6344827586206896\nAccuracy:  0.8974854932301741\nF1-score:  0.9437367303609342\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## LogisticRegression model with Word Embeddings","metadata":{}},{"cell_type":"markdown","source":"#### Word2Vec from scratch","metadata":{}},{"cell_type":"code","source":"def build_corpus(data):\n    \"Creates a list of lists containing words from each sentence\"\n    corpus = []\n    for sentence in data:\n        word_list = sentence.split(\" \")\n        corpus.append(word_list)    \n           \n    return corpus\n\ncorpus = build_corpus(df['text_normalized'])\ncorpus[0]\n\n# vector_size - Dimensionality of the word vectors\n# window - Maximum distance between the current and predicted word within a sentence\n# min_count - Ignores all words with total frequency lower than this\n\nmodel_from_scratch = word2vec.Word2Vec(corpus, vector_size=300, window=10, min_count=20, workers=4)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:37:42.333906Z","iopub.execute_input":"2024-10-02T18:37:42.334419Z","iopub.status.idle":"2024-10-02T18:37:42.608197Z","shell.execute_reply.started":"2024-10-02T18:37:42.334345Z","shell.execute_reply":"2024-10-02T18:37:42.607066Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"#### Pretrained Word2Vec","metadata":{}},{"cell_type":"code","source":"pretrained_model_path = '/kaggle/input/googlenewsvectorsnegative300/GoogleNews-vectors-negative300.bin'\n\n# Завантаження моделі Word2Vec із файлу\npretrained_model = KeyedVectors.load_word2vec_format(pretrained_model_path, binary=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:37:42.609615Z","iopub.execute_input":"2024-10-02T18:37:42.609984Z","iopub.status.idle":"2024-10-02T18:38:35.768275Z","shell.execute_reply.started":"2024-10-02T18:37:42.609945Z","shell.execute_reply":"2024-10-02T18:38:35.766973Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"#### Model training","metadata":{}},{"cell_type":"code","source":"# Function to convert a text into an embedding vector (average of word vectors)\ndef text_to_embedding(text, model):\n    words = text.split()\n    word_vectors = [model[word] for word in words if word in model]\n    if word_vectors:\n        return np.mean(word_vectors, axis=0)\n    else:\n        return np.zeros(model.vector_size)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:38:35.769809Z","iopub.execute_input":"2024-10-02T18:38:35.770186Z","iopub.status.idle":"2024-10-02T18:38:35.777577Z","shell.execute_reply.started":"2024-10-02T18:38:35.770147Z","shell.execute_reply":"2024-10-02T18:38:35.776234Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def train_and_evaluate_model(df, model):\n    \n    # Convert dataset into embedding vectors\n    X = np.array([text_to_embedding(text, model) for text in df['text_normalized']])\n    y = df['score']\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n    \n    # Train a Logistic Regression model\n    model = LogisticRegression(random_state=42, class_weight='balanced')\n    model.fit(X_train, y_train)\n    \n    predictions = model.predict(X_test)\n    \n    print('AUC: ', roc_auc_score(y_test, predictions))\n    print('Accuracy: ', accuracy_score(y_test, predictions))\n    print('F1-score: ', f1_score(y_test, predictions))","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:38:35.779165Z","iopub.execute_input":"2024-10-02T18:38:35.779638Z","iopub.status.idle":"2024-10-02T18:38:35.793672Z","shell.execute_reply.started":"2024-10-02T18:38:35.779593Z","shell.execute_reply":"2024-10-02T18:38:35.792429Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"train_and_evaluate_model(df, model_from_scratch.wv)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:38:35.795145Z","iopub.execute_input":"2024-10-02T18:38:35.795620Z","iopub.status.idle":"2024-10-02T18:38:36.195060Z","shell.execute_reply.started":"2024-10-02T18:38:35.795564Z","shell.execute_reply":"2024-10-02T18:38:36.193239Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"AUC:  0.9029401570676202\nAccuracy:  0.9216634429400387\nF1-score:  0.9538986909504839\n","output_type":"stream"}]},{"cell_type":"code","source":"train_and_evaluate_model(df, pretrained_model)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:38:36.197723Z","iopub.execute_input":"2024-10-02T18:38:36.199048Z","iopub.status.idle":"2024-10-02T18:38:36.737831Z","shell.execute_reply.started":"2024-10-02T18:38:36.198960Z","shell.execute_reply":"2024-10-02T18:38:36.733434Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"AUC:  0.9225778363893046\nAccuracy:  0.9274661508704062\nF1-score:  0.9572162007986309\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## LogisticRegression results","metadata":{}},{"cell_type":"code","source":"data = {\n    'Model': [\n        'BoW (original data)', \n        'BoW (normalized data)', \n        'TF-IDF (original data)', \n        'TF-IDF (normalized data)', \n        'Word2Vec (from scratch)', \n        'Pretrained Word2Vec'\n    ],\n    'AUC': [\n        0.949, 0.922, 0.903, 0.869, 0.903, 0.923\n    ],\n    'Accuracy': [\n        0.9826, 0.9758, 0.9729, 0.9584, 0.9217, 0.9275\n    ],\n    'F1-score': [\n        0.9899, 0.9861, 0.9845, 0.9762, 0.9539, 0.9572\n    ]\n}\n\ndf_results = pd.DataFrame(data).sort_values(by='AUC', ascending=False)\n\nprint(df_results)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T19:08:38.200658Z","iopub.execute_input":"2024-10-02T19:08:38.201127Z","iopub.status.idle":"2024-10-02T19:08:38.215757Z","shell.execute_reply.started":"2024-10-02T19:08:38.201082Z","shell.execute_reply":"2024-10-02T19:08:38.214451Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"                      Model    AUC  Accuracy  F1-score\n0       BoW (original data)  0.949    0.9826    0.9899\n5       Pretrained Word2Vec  0.923    0.9275    0.9572\n1     BoW (normalized data)  0.922    0.9758    0.9861\n2    TF-IDF (original data)  0.903    0.9729    0.9845\n4   Word2Vec (from scratch)  0.903    0.9217    0.9539\n3  TF-IDF (normalized data)  0.869    0.9584    0.9762\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Висновки","metadata":{}},{"cell_type":"markdown","source":"Найкраща модель - **BoW** з n-грамами (1,2) на оригінальних текстах показала найвищі метрики:\n\n**AUC: 0.949<br>\nAccuracy: 0.9826<br>\nF1-score: 0.9899**\n\nЦе означає, що модель, яка використовує BoW з великими n-грамами, краще розуміє контекст і особливості тексту, що робить її найбільш точною для нашої задачі класифікації спаму.\n\n**Pretrained Word2Vec** показав **AUC 0.923** і **Accuracy 0.9275**, що є досить хорошими результатами. **Word2Vec**, **тренований з нуля**, має нижчі результати з **AUC 0.903** та **Accuracy 0.9217**. Це означає, що попередньо навчена модель може краще захоплювати семантичні зв'язки, ніж модель, тренована лише на цьому невеликому наборі даних.\n\n**Переваги та недоліки підходів:**\n\n**BoW**: простий і ефективний для задач класифікації, але може не враховувати семантичні зв'язки між словами.\n\n**TF-IDF**: підсилює важливість унікальних слів і зменшує вплив часто вживаних, але менш ефективний у розумінні контексту, ніж Word2Vec.\n\n**Word2Vec**: розуміє семантичні зв'язки між словами, краще підходить для складних текстів і довгих контекстів, але потрібні великі дані для ефективного тренування моделі з нуля. Попередньо навчена модель може краще працювати та класифікувати дані.\n\n**Вдосконалення моделі:**\n\n- можна спробувати змінити налаштування гіперпараметрів для BoW або TF-IDF\n- для Word2Vec можна тренувати модель на більшому корпусі текстів або спробувати інші моделі ембедингів\n- використання більш складних моделей класифікації.","metadata":{}}]}